# docker/Dockerfile
FROM nvidia/cuda:11.8-devel-ubuntu20.04

# Variables d'environnement
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

# Installation des d√©pendances syst√®me
RUN apt-get update && apt-get install -y \
    python3.9 \
    python3.9-dev \
    python3-pip \
    git \
    wget \
    curl \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libglu1-mesa \
    libxi6 \
    libxmu6 \
    && rm -rf /var/lib/apt/lists/*

# Installation de Blender (headless)
RUN wget -q https://download.blender.org/release/Blender3.6/blender-3.6.0-linux-x64.tar.xz && \
    tar -xf blender-3.6.0-linux-x64.tar.xz && \
    mv blender-3.6.0-linux-x64 /opt/blender && \
    ln -s /opt/blender/blender /usr/local/bin/blender && \
    rm blender-3.6.0-linux-x64.tar.xz

# Configuration Python
RUN python3.9 -m pip install --upgrade pip setuptools wheel

# Cr√©ation du r√©pertoire de travail
WORKDIR /app

# Copie des requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Installation de PyTorch avec support CUDA
RUN pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Copie du code source
COPY . .

# Installation du package
RUN pip install -e .

# Cr√©ation des dossiers n√©cessaires
RUN mkdir -p /app/data/models /app/data/temp /app/logs

# T√©l√©chargement des mod√®les pr√©-entra√Æn√©s (si disponibles)
# RUN python scripts/download_models.py

# Exposition du port
EXPOSE 8000

# Variables d'environnement pour l'application
ENV PYTHONPATH=/app
ENV MODEL_PATH=/app/data/models
ENV TEMP_PATH=/app/data/temp

# Commande de d√©marrage
CMD ["python", "-m", "src.api.main"]

# docker/docker-compose.yml
version: '3.8'

services:
  sketch3d-api:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ../data:/app/data
      - ../logs:/app/logs
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONPATH=/app
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data

  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: sketch3d
      POSTGRES_USER: sketch3d_user
      POSTGRES_PASSWORD: sketch3d_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  redis_data:
  postgres_data:

# scripts/setup_environment.sh
#!/bin/bash

# Script de configuration de l'environnement de d√©veloppement

set -e

echo "=== Configuration de l'environnement Sketch-to-3D ==="

# V√©rification de Python 3.9+
python_version=$(python3 --version 2>&1 | grep -o '[0-9]\+\.[0-9]\+' | head -1)
required_version="3.9"

if [ "$(printf '%s\n' "$required_version" "$python_version" | sort -V | head -n1)" != "$required_version" ]; then
    echo "Erreur: Python 3.9+ requis. Version d√©tect√©e: $python_version"
    exit 1
fi

echo "‚úì Python version OK: $python_version"

# Cr√©ation de l'environnement virtuel
if [ ! -d "venv" ]; then
    echo "Cr√©ation de l'environnement virtuel..."
    python3 -m venv venv
fi

# Activation de l'environnement virtuel
source venv/bin/activate
echo "‚úì Environnement virtuel activ√©"

# Mise √† jour de pip
pip install --upgrade pip setuptools wheel

# Installation des d√©pendances
echo "Installation des d√©pendances Python..."
pip install -r requirements.txt

# V√©rification de CUDA (optionnel)
if command -v nvidia-smi &> /dev/null; then
    echo "‚úì NVIDIA GPU d√©tect√©:"
    nvidia-smi --query-gpu=name --format=csv,noheader
    
    # Installation de PyTorch avec CUDA
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
else
    echo "‚ö† Aucun GPU NVIDIA d√©tect√©, installation PyTorch CPU"
    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
fi

# Cr√©ation des dossiers n√©cessaires
echo "Cr√©ation de la structure des dossiers..."
mkdir -p data/{datasets,models,temp}
mkdir -p logs
mkdir -p checkpoints
mkdir -p src/models/model_weights

echo "‚úì Dossiers cr√©√©s"

# Installation d'Open3D
echo "Installation d'Open3D..."
pip install open3d

# Installation de Trimesh
pip install trimesh

# Test des imports principaux
echo "Test des imports..."
python3 -c "
import torch
import cv2
import numpy as np
import open3d as o3d
import trimesh
from PIL import Image
print('‚úì Tous les imports principaux fonctionnent')
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA disponible: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
"

# T√©l√©chargement des datasets de base (optionnel)
echo "Voulez-vous t√©l√©charger les datasets de d√©monstration? (y/N)"
read -r download_data
if [[ $download_data =~ ^[Yy]$ ]]; then
    echo "T√©l√©chargement des datasets..."
    python3 scripts/download_datasets.py
fi

echo ""
echo "=== Configuration termin√©e avec succ√®s! ==="
echo ""
echo "Pour d√©marrer le d√©veloppement:"
echo "1. source venv/bin/activate"
echo "2. python -m src.api.main"
echo ""
echo "Pour entra√Æner les mod√®les:"
echo "python scripts/train_models.py --model all"
echo ""
echo "Pour lancer les tests:"
echo "pytest tests/"

# scripts/download_datasets.py
#!/usr/bin/env python3
"""
Script de t√©l√©chargement et pr√©paration des datasets
"""

import requests
import numpy as np
from pathlib import Path
import logging
import argparse
from tqdm import tqdm
import zipfile
import json

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def download_file(url: str, destination: Path, description: str = ""):
    """T√©l√©charge un fichier avec barre de progression"""
    response = requests.get(url, stream=True)
    total_size = int(response.headers.get('content-length', 0))
    
    with open(destination, 'wb') as f, tqdm(
        desc=description,
        total=total_size,
        unit='B',
        unit_scale=True,
        unit_divisor=1024,
    ) as pbar:
        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                f.write(chunk)
                pbar.update(len(chunk))

def download_quickdraw_samples():
    """T√©l√©charge des √©chantillons du dataset QuickDraw"""
    logger.info("T√©l√©chargement des √©chantillons QuickDraw...")
    
    data_dir = Path("data/datasets/quickdraw")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # Liste des cat√©gories populaires pour d√©mo
    demo_categories = [
        "cat", "dog", "car", "house", "tree", "flower", "bird", "fish",
        "sun", "moon", "star", "cloud", "mountain", "river", "bridge",
        "chair", "table", "bed", "door", "window", "book", "phone",
        "computer", "camera", "bicycle", "airplane", "boat", "train"
    ]
    
    base_url = "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap"
    
    for category in demo_categories:
        file_url = f"{base_url}/{category.replace(' ', '%20')}.npy"
        file_path = data_dir / f"{category}.npy"
        
        if not file_path.exists():
            try:
                logger.info(f"T√©l√©chargement de {category}...")
                download_file(file_url, file_path, f"QuickDraw - {category}")
                
                # Limitation √† 1000 √©chantillons pour la d√©mo
                data = np.load(file_path)
                if len(data) > 1000:
                    data = data[:1000]
                    np.save(file_path, data)
                
                logger.info(f"‚úì {category}: {len(data)} √©chantillons")
                
            except Exception as e:
                logger.error(f"Erreur t√©l√©chargement {category}: {e}")
        else:
            logger.info(f"‚úì {category} d√©j√† pr√©sent")

def create_synthetic_depth_data():
    """Cr√©e des donn√©es synth√©tiques pour l'entra√Ænement du depth estimator"""
    logger.info("G√©n√©ration de donn√©es synth√©tiques depth...")
    
    sketch_dir = Path("data/datasets/synthetic/sketches")
    depth_dir = Path("data/datasets/synthetic/depths")
    
    sketch_dir.mkdir(parents=True, exist_ok=True)
    depth_dir.mkdir(parents=True, exist_ok=True)
    
    # G√©n√©ration de formes g√©om√©triques simples avec leurs depth maps
    shapes = ['cube', 'sphere', 'cylinder', 'cone', 'pyramid']
    
    for i, shape in enumerate(shapes):
        for sample in range(20):  # 20 √©chantillons par forme
            # G√©n√©ration d'un sketch synth√©tique
            sketch, depth = generate_synthetic_shape(shape, size=256)
            
            filename = f"{shape}_{sample:03d}.png"
            
            # Sauvegarde
            sketch_path = sketch_dir / filename
            depth_path = depth_dir / filename
            
            cv2.imwrite(str(sketch_path), sketch)
            cv2.imwrite(str(depth_path), depth)
    
    logger.info("‚úì Donn√©es synth√©tiques g√©n√©r√©es")

def generate_synthetic_shape(shape_type: str, size: int = 256):
    """G√©n√®re un sketch et sa depth map pour une forme g√©om√©trique"""
    import cv2
    
    sketch = np.zeros((size, size), dtype=np.uint8)
    depth = np.zeros((size, size), dtype=np.uint8)
    
    center_x, center_y = size // 2, size // 2
    
    if shape_type == 'cube':
        # Cube en perspective
        pts = np.array([
            [center_x-60, center_y-40],
            [center_x+40, center_y-40],
            [center_x+60, center_y+40],
            [center_x-40, center_y+40]
        ], dtype=np.int32)
        
        cv2.polylines(sketch, [pts], True, 255, 2)
        
        # Depth map: plus fonc√© au centre
        cv2.fillPoly(depth, [pts], 200)
        
    elif shape_type == 'sphere':
        # Cercle
        cv2.circle(sketch, (center_x, center_y), 50, 255, 2)
        
        # Depth map: gradient radial
        y, x = np.ogrid[:size, :size]
        mask = (x - center_x)**2 + (y - center_y)**2 <= 50**2
        depth[mask] = 255 - ((x - center_x)**2 + (y - center_y)**2)[mask] * 255 // (50**2)
        
    elif shape_type == 'cylinder':
        # Rectangle avec ellipse en haut
        cv2.rectangle(sketch, (center_x-40, center_y-20), (center_x+40, center_y+40), 255, 2)
        cv2.ellipse(sketch, (center_x, center_y-20), (40, 10), 0, 0, 360, 255, 2)
        
        # Depth map simple
        cv2.rectangle(depth, (center_x-40, center_y-20), (center_x+40, center_y+40), 180, -1)
        
    # Ajout de bruit pour plus de r√©alisme
    noise = np.random.normal(0, 10, sketch.shape).astype(np.uint8)
    sketch = np.clip(sketch + noise, 0, 255)
    
    return sketch, depth

def download_sample_3d_models():
    """T√©l√©charge quelques mod√®les 3D de r√©f√©rence"""
    logger.info("T√©l√©chargement de mod√®les 3D de r√©f√©rence...")
    
    models_dir = Path("data/datasets/reference_3d")
    models_dir.mkdir(parents=True, exist_ok=True)
    
    # URLs de mod√®les 3D simples (Creative Commons)
    reference_models = [
        {
            "name": "cube.obj",
            "url": "https://raw.githubusercontent.com/McNopper/OpenGL/master/Binaries/cube.obj"
        }
        # Ajoutez d'autres URLs de mod√®les si disponibles
    ]
    
    for model in reference_models:
        model_path = models_dir / model["name"]
        if not model_path.exists():
            try:
                download_file(model["url"], model_path, f"Mod√®le 3D - {model['name']}")
                logger.info(f"‚úì {model['name']} t√©l√©charg√©")
            except Exception as e:
                logger.warning(f"Impossible de t√©l√©charger {model['name']}: {e}")

def create_dataset_info():
    """Cr√©e un fichier d'information sur les datasets"""
    info = {
        "datasets": {
            "quickdraw": {
                "description": "Google QuickDraw dataset - √©chantillons de sketches",
                "categories": 28,
                "samples_per_category": 1000,
                "format": "numpy arrays (28x28 bitmap)",
                "usage": "Classification de sketches"
            },
            "synthetic": {
                "description": "Donn√©es synth√©tiques pour depth estimation",
                "shapes": ["cube", "sphere", "cylinder", "cone", "pyramid"],
                "samples_per_shape": 20,
                "format": "PNG images (256x256)",
                "usage": "Entra√Ænement depth estimator"
            }
        },
        "total_size": "~50MB",
        "last_updated": "2024-01-01"
    }
    
    with open("data/datasets/dataset_info.json", 'w') as f:
        json.dump(info, f, indent=2)

def main():
    parser = argparse.ArgumentParser(description='T√©l√©chargement des datasets')
    parser.add_argument('--quickdraw', action='store_true', help='T√©l√©charger QuickDraw samples')
    parser.add_argument('--synthetic', action='store_true', help='G√©n√©rer donn√©es synth√©tiques')
    parser.add_argument('--models', action='store_true', help='T√©l√©charger mod√®les 3D')
    parser.add_argument('--all', action='store_true', help='Tout t√©l√©charger')
    
    args = parser.parse_args()
    
    if args.all or not any([args.quickdraw, args.synthetic, args.models]):
        # Par d√©faut, tout faire
        args.quickdraw = args.synthetic = args.models = True
    
    try:
        if args.quickdraw:
            download_quickdraw_samples()
        
        if args.synthetic:
            create_synthetic_depth_data()
        
        if args.models:
            download_sample_3d_models()
        
        create_dataset_info()
        
        logger.info("‚úì T√©l√©chargement termin√© avec succ√®s!")
        
    except Exception as e:
        logger.error(f"Erreur lors du t√©l√©chargement: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())

# scripts/run_tests.sh
#!/bin/bash

# Script de tests automatis√©s

set -e

echo "=== Tests Sketch-to-3D ==="

# Activation de l'environnement virtuel
if [ -d "venv" ]; then
    source venv/bin/activate
    echo "‚úì Environnement virtuel activ√©"
fi

# Installation des d√©pendances de test si n√©cessaire
pip install pytest pytest-cov pytest-mock

# Tests unitaires
echo "Ex√©cution des tests unitaires..."
python -m pytest tests/ -v --cov=src --cov-report=html --cov-report=term

# Test de l'API
echo "Test de l'API..."
python -c "
import requests
import time
import subprocess
import signal
import os

# D√©marrage du serveur en arri√®re-plan
server = subprocess.Popen(['python', '-m', 'src.api.main'], 
                         stdout=subprocess.DEVNULL, 
                         stderr=subprocess.DEVNULL)

# Attente du d√©marrage
time.sleep(5)

try:
    # Test de base
    response = requests.get('http://localhost:8000/')
    assert response.status_code == 200
    print('‚úì API accessible')
    
    # Test health check
    response = requests.get('http://localhost:8000/health')
    assert response.status_code == 200
    print('‚úì Health check OK')
    
except Exception as e:
    print(f'‚úó Test API √©chou√©: {e}')
finally:
    # Arr√™t du serveur
    server.terminate()
    server.wait()
"

# Test des mod√®les
echo "Test des mod√®les..."
python -c "
from src.models.sketch_classifier import SketchClassifier
from src.models.depth_estimator import DepthEstimator
import torch

# Test classifier
classifier = SketchClassifier(num_classes=10)
test_input = torch.randn(1, 1, 224, 224)
output = classifier(test_input)
assert output.shape == (1, 10)
print('‚úì Classifier fonctionne')

# Test depth estimator  
depth_model = DepthEstimator()
test_input = torch.randn(1, 1, 512, 512)
output = depth_model(test_input)
assert output.shape == (1, 1, 512, 512)
print('‚úì Depth estimator fonctionne')
"

# Test des utilitaires
echo "Test des utilitaires..."
python -c "
from src.utils.image_processing import normalize_sketch, clean_sketch
from src.utils.validation import validate_sketch_input
import numpy as np

# Test image processing
test_image = np.random.randint(0, 255, (100, 100), dtype=np.uint8)
normalized = normalize_sketch(test_image)
assert normalized.shape == (512, 512)
print('‚úì Image processing OK')

# Test validation
assert validate_sketch_input(test_image) == True
print('‚úì Validation OK')
"

# Test de g√©n√©ration de mesh
echo "Test de g√©n√©ration de mesh..."
python -c "
from src.core.mesh_generator import MeshGenerator
import numpy as np

config = {
    'voxel_resolution': 32,
    'smoothing_iterations': 1,
    'min_mesh_faces': 10
}

generator = MeshGenerator(config)
depth_map = np.random.rand(64, 64)
sketch_mask = np.ones((64, 64))
class_info = {'class_name': 'cube', 'confidence': 0.8}

try:
    mesh = generator.generate_mesh_from_depth(depth_map, sketch_mask, class_info)
    print(f'‚úì Mesh g√©n√©r√© avec {len(mesh.vertices)} vertices')
except Exception as e:
    print(f'‚ö† Mesh generation: {e} (normal avec donn√©es al√©atoires)')
"

echo ""
echo "=== Tests termin√©s ==="
echo "Consultez htmlcov/index.html pour le rapport de couverture d√©taill√©"

# Makefile
.PHONY: help install test run clean docker

help: ## Affiche cette aide
	@grep -E '^[a-zA-Z_-]+:.*?## .*$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-30s\033[0m %s\n", $1, $2}'

install: ## Installation compl√®te de l'environnement
	@echo "Installation de l'environnement..."
	@bash scripts/setup_environment.sh

download-data: ## T√©l√©chargement des datasets
	@echo "T√©l√©chargement des datasets..."
	@python scripts/download_datasets.py --all

train: ## Entra√Ænement des mod√®les
	@echo "Entra√Ænement des mod√®les..."
	@python scripts/train_models.py --model all

test: ## Ex√©cution des tests
	@echo "Ex√©cution des tests..."
	@bash scripts/run_tests.sh

run: ## D√©marrage de l'API
	@echo "D√©marrage de l'API Sketch-to-3D..."
	@python -m src.api.main

run-dev: ## D√©marrage en mode d√©veloppement
	@echo "D√©marrage en mode d√©veloppement..."
	@uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

docker-build: ## Construction de l'image Docker
	@echo "Construction de l'image Docker..."
	@docker build -f docker/Dockerfile -t sketch3d:latest .

docker-run: ## D√©marrage avec Docker Compose
	@echo "D√©marrage avec Docker Compose..."
	@docker-compose -f docker/docker-compose.yml up -d

docker-stop: ## Arr√™t des conteneurs Docker
	@docker-compose -f docker/docker-compose.yml down

clean: ## Nettoyage des fichiers temporaires
	@echo "Nettoyage..."
	@find . -type f -name "*.pyc" -delete
	@find . -type d -name "__pycache__" -exec rm -rf {} +
	@find . -type d -name "*.egg-info" -exec rm -rf {} +
	@rm -rf build/ dist/ .coverage htmlcov/ .pytest_cache/

lint: ## V√©rification du code avec flake8
	@echo "V√©rification du code..."
	@flake8 src/ tests/ --max-line-length=100 --ignore=E203,W503

format: ## Formatage du code avec black
	@echo "Formatage du code..."
	@black src/ tests/ scripts/ --line-length=100

setup-dev: install download-data ## Configuration compl√®te pour d√©veloppement
	@echo "Configuration de d√©veloppement termin√©e!"
	@echo "Utilisez 'make run-dev' pour d√©marrer"

# README.md pour le projet
# Sketch-to-3D Backend

Pipeline d'intelligence artificielle pour convertir des dessins √† main lev√© en mod√®les 3D.

## üöÄ D√©marrage Rapide

```bash
# Installation compl√®te
make setup-dev

# D√©marrage de l'API
make run-dev

# Tests
make test
```

## üìÅ Architecture

```
sketch3d-backend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/          # API FastAPI  
‚îÇ   ‚îú‚îÄ‚îÄ core/         # Pipeline principal
‚îÇ   ‚îú‚îÄ‚îÄ models/       # Mod√®les PyTorch
‚îÇ   ‚îî‚îÄ‚îÄ utils/        # Utilitaires
‚îú‚îÄ‚îÄ scripts/          # Scripts d'entra√Ænement
‚îú‚îÄ‚îÄ docker/           # Configuration Docker
‚îî‚îÄ‚îÄ tests/            # Tests automatis√©s
```

## ü§ñ Pipeline IA

1. **Classification** : Identification du type d'objet (ResNet-18)
2. **Depth Estimation** : G√©n√©ration de carte de profondeur (U-Net)
3. **Mesh Generation** : Reconstruction 3D (Marching Cubes)
4. **Export** : Fichier .blend pour Blender

## üîß API Endpoints

- `POST /api/v1/sketch/process` : Traitement d'un sketch
- `GET /api/v1/sketch/{id}/status` : Statut du traitement  
- `GET /api/v1/sketch/{id}/download` : T√©l√©chargement du .blend

## üìä Performance

- **Temps de traitement** : <30s par sketch
- **Classification** : >90% pr√©cision  
- **Support GPU** : CUDA 11.8+
- **Formats** : JPG, PNG ‚Üí .blend

## üê≥ Docker

```bash
# Construction
make docker-build

# D√©marrage complet
make docker-run
```

## üìà D√©veloppement

- **Tests** : `make test`
- **Linting** : `make lint`  
- **Format** : `make format`
- **Clean** : `make clean`